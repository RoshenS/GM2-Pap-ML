{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The code below trains an efficientnetB3 model based on the training data selected for a chosen number of epochs. It takes reference to https://www.kaggle.com/code/gpiosenka/papilledema-f1-score-98/notebook and has changes that improve the accuracy of the model to 99.27% when trained on the original dataset, namely the training set does not have to be trimmed as there is not a significant class imbalance."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"import\"></a>\n","# <center>Import Modules</center>"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T03:13:33.844380Z","iopub.status.busy":"2022-07-15T03:13:33.844026Z","iopub.status.idle":"2022-07-15T03:13:33.853719Z","shell.execute_reply":"2022-07-15T03:13:33.852749Z","shell.execute_reply.started":"2022-07-15T03:13:33.844343Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","import time\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dense, Dropout,BatchNormalization\n","from keras.optimizers import Adamax\n","from keras import regularizers\n","from keras.models import Model"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"makedf\"></a>\n","# <center>Reading images and creating Train/Test/Valid split</center>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The training and validation datasets will be used during the training of the model, while the test set will be used to test the accuracy of the model on images not seen before. A seed is given to the train_test_split function to ensure that on every run, the images used for testing are constant. This information is saved in the test_paths file and will be utilized when training and testing models on the different quality levels of images."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T03:13:33.865967Z","iopub.status.busy":"2022-07-15T03:13:33.865674Z","iopub.status.idle":"2022-07-15T03:13:34.112045Z","shell.execute_reply":"2022-07-15T03:13:34.111035Z","shell.execute_reply.started":"2022-07-15T03:13:33.865939Z"},"trusted":true},"outputs":[],"source":["subject = 'Original'\n","\n","sdir=r'Data\\\\' + subject\n","filepaths = []\n","labels=[]\n","#relpath = []\n","classlist=sorted(os.listdir(sdir))  \n","for klass in classlist:\n","    classpath=os.path.join(sdir, klass)\n","    flist=os.listdir(classpath)        \n","    for f in flist:\n","        fpath=os.path.join(classpath,f)\n","        filepaths.append(fpath)\n","        labels.append(klass)\n","        #relpath.append(os.path.join(klass, f))\n","Fseries=pd.Series(filepaths, name='filepaths')\n","Lseries=pd.Series(labels, name='labels')\n","Rseries=pd.Series(relpath,name='paths') #del       \n","df=pd.concat([Fseries, Lseries], axis=1)\n","\n","    \n","train_df, dummy_df=train_test_split(df, train_size=.8, shuffle=True, random_state=23, stratify=df['labels'])\n","valid_df, test_df=train_test_split(dummy_df, train_size=.5, shuffle=True, random_state=23, stratify=dummy_df['labels'])\n","\n","#test_df[['paths', 'labels']].to_excel('Information\\\\Test_paths.xlsx',index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"generators\"></a>\n","# <center>Create the Train/Test/Valid gen</center>"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This module augments the images from the training split and converts the training, validation and testing splits into a format that can be used by the efficientnetB3 model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T03:13:34.161586Z","iopub.status.busy":"2022-07-15T03:13:34.160886Z","iopub.status.idle":"2022-07-15T03:13:34.254621Z","shell.execute_reply":"2022-07-15T03:13:34.253562Z","shell.execute_reply.started":"2022-07-15T03:13:34.161550Z"},"trusted":true},"outputs":[],"source":["img_size=(240,240)\n","\n","#Image Augmentation\n","trgen=ImageDataGenerator(horizontal_flip=True,rotation_range=20, width_shift_range=.2,\n","                        height_shift_range=.2, zoom_range=.2 )\n","t_and_v_gen=ImageDataGenerator()\n","\n","#creating train gen\n","train_gen=trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,\n","                                   class_mode='categorical', color_mode='rgb', shuffle=True)\n","\n","#creating valid gen\n","valid_gen=t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size,\n","                                          class_mode='categorical', color_mode='rgb', shuffle=False)\n","\n","# for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n","# this insures that we go through all the sample in the test set exactly once.\n","length=len(test_df)\n","test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n","test_steps=int(length/test_batch_size)\n","\n","test_gen=t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size,\n","                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n","\n","#info used later\n","classes=list(train_gen.class_indices.keys())\n","class_indices=list(train_gen.class_indices.values())\n","class_count=len(classes)\n","labels=test_gen.labels\n","print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"model\"></a>\n","# <center>Create a model using EfficientNetB3<center>\n","The base of the model has been trained in the ImageNet dataset and is trainable. There is a dropout rate of 0.4, and low learning rate of 0.001 to prevent overtraining."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T03:13:37.766198Z","iopub.status.busy":"2022-07-15T03:13:37.765610Z","iopub.status.idle":"2022-07-15T03:13:40.248232Z","shell.execute_reply":"2022-07-15T03:13:40.247244Z","shell.execute_reply.started":"2022-07-15T03:13:37.766158Z"},"trusted":true},"outputs":[],"source":["img_shape=(img_size[0], img_size[1], 3)\n","model_name='EfficientNetB3'\n","base_model=tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n","\n","base_model.trainable=True\n","\n","x=base_model.output\n","x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n","x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n","          bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n","x=Dropout(rate=.4, seed=123)(x)       \n","output=Dense(class_count, activation='softmax')(x)\n","model=Model(inputs=base_model.input, outputs=output)\n","lr=.001 # start with this learning rate\n","model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy']) "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"callback\"></a>\n","# <center>Keras callback</center>\n","This callback allows the user to set a number of epochs to contuinue training for (if swlf.ask=True), to modify the learining rate, or to halt training. At the end of training the model weights are set to the weights for the epoch that achieved the lowest validation loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T03:13:40.250172Z","iopub.status.busy":"2022-07-15T03:13:40.249807Z","iopub.status.idle":"2022-07-15T03:13:40.270052Z","shell.execute_reply":"2022-07-15T03:13:40.269076Z","shell.execute_reply.started":"2022-07-15T03:13:40.250136Z"},"trusted":true},"outputs":[],"source":["class LR_ASK(keras.callbacks.Callback):\n","    def __init__ (self, model, epochs,  ask_epoch): # initialization of the callback\n","        super(LR_ASK, self).__init__()\n","        self.model=model               \n","        self.ask_epoch=ask_epoch\n","        self.epochs=epochs\n","        self.ask=True # if True query the user on a specified epoch\n","        self.lowest_vloss=np.inf\n","        self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n","        self.best_epoch=1\n","        \n","        \n","    def on_train_begin(self, logs=None): # this runs on the beginning of training\n","        if self.ask_epoch == 0: \n","            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n","            self.ask_epoch=1\n","        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n","            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n","            self.ask=False # do not query the user\n","        if self.epochs == 1:\n","            self.ask=False # running only for 1 epoch so do not query user\n","        else:\n","            print('Training will proceed until epoch', ask_epoch,' then you will be asked to') \n","            print(' enter H to halt training or enter an integer for how many more epochs to run then be asked again')  \n","        self.start_time= time.time() # set the time at which training started\n","        \n","    def on_train_end(self, logs=None):   # runs at the end of training  \n","        print('loading model with weights from epoch ', self.best_epoch)\n","        self.model.set_weights(self.best_weights) # set the weights of the model to the best weights\n","        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted         \n","        hours = tr_duration // 3600\n","        minutes = (tr_duration - (hours * 3600)) // 60\n","        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n","        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n","        print (msg, flush=True) # print out training duration time\n","        \n","    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n","        v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n","        if v_loss< self.lowest_vloss:\n","            if epoch !=0:\n","                pimprov= (self.lowest_vloss - v_loss) * 100/self.lowest_vloss\n","            else:\n","                pimprov=0\n","            self.lowest_vloss=v_loss\n","            self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n","            self.best_epoch=epoch + 1\n","             \n","            print (f'\\n validation loss of {v_loss:7.4f} is {pimprov:7.2f} % below lowest loss, saving weights from epoch {str(epoch + 1):3s} as best weights')\n","        else:\n","            print (f'\\n validation loss of {v_loss:7.4f} is above lowest loss of {self.lowest_vloss:7.4f} keeping weights from epoch {str(self.best_epoch)} as best weights')\n","        \n","        if self.ask: # are the conditions right to query the user?\n","            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n","                print('\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again')\n","                ans=input()\n","                \n","                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n","                    print ('you entered ', ans, ' Training halted on epoch ', epoch+1, ' due to user input\\n', flush=True)\n","                    self.model.stop_training = True # halt training\n","                else: # user wants to continue training\n","                    self.ask_epoch += int(ans)\n","                    if self.ask_epoch > self.epochs:\n","                        print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n","                    else:\n","                        print ('you entered ', ans, ' Training will continue to epoch ', self.ask_epoch, flush=True)\n","                        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n","                        print(f'current LR is  {lr:7.5f}  hit enter to keep  this LR or enter a new LR')\n","                        ans=input()\n","                        if ans =='':\n","                            print (f'keeping current LR of {lr:7.5f}')\n","                        else:\n","                            new_lr=float(ans)\n","                            tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n","                            print(' changing LR to ', ans)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"callbacks\"></a>\n","# <center>Instantiate custom callback</center>\n","Change the number of epochs for the training to run for and when the user should be prompted."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T03:13:40.272267Z","iopub.status.busy":"2022-07-15T03:13:40.271645Z","iopub.status.idle":"2022-07-15T03:13:40.410595Z","shell.execute_reply":"2022-07-15T03:13:40.409656Z","shell.execute_reply.started":"2022-07-15T03:13:40.272228Z"},"trusted":true},"outputs":[],"source":["epochs=40 #number of epochs to train for\n","ask_epoch=5 #number of epochs before user is asked\n","ask=LR_ASK(model, epochs,  ask_epoch)\n","callbacks=[ask]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"train\"></a>\n","# <center>Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T03:13:40.412690Z","iopub.status.busy":"2022-07-15T03:13:40.412131Z","iopub.status.idle":"2022-07-15T03:22:24.193322Z","shell.execute_reply":"2022-07-15T03:22:24.192359Z","shell.execute_reply.started":"2022-07-15T03:13:40.412652Z"},"trusted":true},"outputs":[],"source":["history=model.fit(x=train_gen,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=valid_gen,\n","               validation_steps=None,  shuffle=False,  initial_epoch=0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"plot\"></a>\n","# <center>Plot and save the training data</center>\n","This module plots the Training and Validation Loss and Accuracy, and saves it under the Model Training Information folder"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T03:22:24.197565Z","iopub.status.busy":"2022-07-15T03:22:24.197027Z","iopub.status.idle":"2022-07-15T03:22:24.683828Z","shell.execute_reply":"2022-07-15T03:22:24.682918Z","shell.execute_reply.started":"2022-07-15T03:22:24.197517Z"},"trusted":true},"outputs":[],"source":["def tr_plot(tr_data, start_epoch):\n","    #Plot the training and validation data\n","    tacc=tr_data.history['accuracy']\n","    tloss=tr_data.history['loss']\n","    vacc=tr_data.history['val_accuracy']\n","    vloss=tr_data.history['val_loss']\n","    Epoch_count=len(tacc)+ start_epoch\n","    Epochs=[]\n","    for i in range (start_epoch ,Epoch_count):\n","        Epochs.append(i+1)   \n","    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n","    val_lowest=vloss[index_loss]\n","    index_acc=np.argmax(vacc)\n","    acc_highest=vacc[index_acc]\n","    plt.style.use('fivethirtyeight')\n","    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n","    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n","    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n","    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n","    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n","    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n","    axes[0].set_title('Training and Validation Loss')\n","    axes[0].set_xlabel('Epochs')\n","    axes[0].set_ylabel('Loss')\n","    axes[0].legend()\n","    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n","    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n","    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n","    axes[1].set_title('Training and Validation Accuracy')\n","    axes[1].set_xlabel('Epochs')\n","    axes[1].set_ylabel('Accuracy')\n","    axes[1].legend()\n","    plt.tight_layout\n","    plt_name = \"Model trained on \" +subject\n","    fig.suptitle(plt_name, fontsize=20)\n","    plt.savefig(os.path.join(\"Information\\\\Model Training Information\\\\\", plt_name)+'.png')    \n","    plt.show()\n","    \n","tr_plot(history,0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"result\"></a>\n","# <center>Make Predictions on the test set</a>\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Test model on test set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T03:22:24.686316Z","iopub.status.busy":"2022-07-15T03:22:24.685574Z","iopub.status.idle":"2022-07-15T03:22:29.435024Z","shell.execute_reply":"2022-07-15T03:22:29.434139Z","shell.execute_reply.started":"2022-07-15T03:22:24.686273Z"},"trusted":true},"outputs":[],"source":["def predictor(test_gen, test_steps):\n","    y_pred= []\n","    y_true=test_gen.labels\n","    classes=list(test_gen.class_indices.keys())\n","    class_count=len(classes)\n","    errors=0\n","    preds=model.predict(test_gen, verbose=1)\n","    tests=len(preds)    \n","    for i, p in enumerate(preds):        \n","        pred_index=np.argmax(p)         \n","        true_index=test_gen.labels[i]  # labels are integer values        \n","        if pred_index != true_index: # a misclassification has occurred                                           \n","            errors=errors + 1\n","            file=test_gen.filenames[i]            \n","        y_pred.append(pred_index)\n","            \n","    acc=( 1-errors/tests) * 100\n","    print(f'there were {errors} errors in {tests} tests for an accuracy of {acc:6.2f}')\n","    ypred=np.array(y_pred)\n","    ytrue=np.array(y_true)\n","    if class_count <=30:\n","        cm = confusion_matrix(ytrue, ypred )\n","        # plot the confusion matrix\n","        plt.figure(figsize=(12, 8))\n","        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n","        plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n","        plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n","        plt.xlabel(\"Predicted\")\n","        plt.ylabel(\"Actual\")\n","        plt.title(\"Confusion Matrix\")\n","        plt.show()\n","    clr = classification_report(y_true, y_pred, target_names=classes, digits= 4) # create classification report\n","    print(\"Classification Report:\\n----------------------\\n\", clr)\n","    return errors, tests\n","errors, tests=predictor(test_gen, test_steps)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id=\"save\"></a>\n","# <center>Save the model"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Save model as (dataset used to train)_(accuracy on test set).h5 in the Models folder"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-15T03:22:29.437145Z","iopub.status.busy":"2022-07-15T03:22:29.436458Z","iopub.status.idle":"2022-07-15T03:22:30.634596Z","shell.execute_reply":"2022-07-15T03:22:30.633581Z","shell.execute_reply.started":"2022-07-15T03:22:29.437104Z"},"trusted":true},"outputs":[],"source":["acc=str(( 1-errors/tests) * 100)\n","index=acc.rfind('.')\n","acc=acc[:index + 3]\n","save_id= subject + '_' + str(acc)\n","model_save_loc=os.path.join(\"Models\\\\\", save_id)\n","model.save(model_save_loc, save_format='h5')\n","print ('model was saved as ' , model_save_loc )"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"b2bb01db43c92608afe528117be8348869a8bbfc2e823dee3781b388bf5fc44d"}}},"nbformat":4,"nbformat_minor":4}
